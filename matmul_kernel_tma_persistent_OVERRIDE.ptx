//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_90a
.address_size 64

	// .globl	matmul_kernel_tma_persistent_OVERRIDE
.extern .shared .align 16 .b8 global_smem[];

.visible .entry matmul_kernel_tma_persistent_OVERRIDE(
	.param .u64 matmul_kernel_tma_persistent_OVERRIDE_param_0,
	.param .u64 matmul_kernel_tma_persistent_OVERRIDE_param_1,
	.param .u64 matmul_kernel_tma_persistent_OVERRIDE_param_2,
	.param .u32 matmul_kernel_tma_persistent_OVERRIDE_param_3,
	.param .u32 matmul_kernel_tma_persistent_OVERRIDE_param_4,
	.param .u32 matmul_kernel_tma_persistent_OVERRIDE_param_5
)
.maxntid 256, 1, 1
{
	.reg .pred 	%p<41>;
	.reg .b16 	%rs<129>;
	.reg .b32 	%r<329>;
	.reg .f32 	%f<2732>;
	.reg .b64 	%rd<25>;
	.loc	1 312 0
$L__func_begin0:
	.loc	1 312 0

	ld.param.u64 	%rd17, [matmul_kernel_tma_persistent_OVERRIDE_param_1];
	ld.param.u64 	%rd16, [matmul_kernel_tma_persistent_OVERRIDE_param_0];
	// MANUAL OVERRIDE
	tensormap.replace.tile.elemtype.global.b1024.b32 [%rd16], 6;
	tensormap.replace.tile.elemtype.global.b1024.b32 [%rd17], 6;
	fence.proxy.tensormap::generic.release.gpu;
	fence.proxy.tensormap::generic.acquire.gpu [%rd16], 128;
	fence.proxy.tensormap::generic.acquire.gpu [%rd17], 128;
	// END MANUAL OVERRIDE
$L__tmp0:
	.loc	1 321 30
	// begin inline asm
	mov.u32 %r326, %ctaid.x;
	// end inline asm
	ld.param.u32 	%r74, [matmul_kernel_tma_persistent_OVERRIDE_param_3];
	ld.param.u32 	%r75, [matmul_kernel_tma_persistent_OVERRIDE_param_4];
$L__tmp1:
	.loc	2 40 22
	add.s32 	%r76, %r75, 255;
	add.s32 	%r77, %r74, 127;
	.loc	2 40 28
	shr.s32 	%r78, %r77, 31;
	shr.u32 	%r79, %r78, 25;
	add.s32 	%r80, %r77, %r79;
	shr.s32 	%r81, %r80, 7;
	shr.s32 	%r82, %r76, 31;
	shr.u32 	%r83, %r82, 24;
	add.s32 	%r84, %r76, %r83;
	shr.s32 	%r85, %r84, 8;
	ld.param.u32 	%r87, [matmul_kernel_tma_persistent_OVERRIDE_param_5];
$L__tmp2:
	.loc	2 40 22
	add.s32 	%r88, %r87, 63;
$L__tmp3:
	.loc	1 325 28
	mul.lo.s32 	%r89, %r85, %r81;
	.loc	1 327 32
	shr.s32 	%r90, %r88, 31;
	shr.u32 	%r91, %r90, 26;
	add.s32 	%r92, %r88, %r91;
	shr.s32 	%r93, %r92, 6;
	mul.hi.s32 	%r94, %r89, 1041204193;
	.loc	1 328 31
	shr.u32 	%r95, %r94, 31;
	shr.s32 	%r96, %r94, 5;
	add.s32 	%r97, %r96, %r95;
	mul.lo.s32 	%r98, %r97, 132;
	sub.s32 	%r99, %r89, %r98;
	.loc	1 328 19
	setp.lt.s32 	%p10, %r326, %r99;
	.loc	1 328 7
	selp.u32 	%r100, 1, 0, %p10;
	add.s32 	%r101, %r97, %r100;
	.loc	1 339 38
	shl.b32 	%r6, %r85, 3;
	.loc	1 343 32
	mul.lo.s32 	%r3, %r101, %r93;
	.loc	1 344 38
	add.s32 	%r4, %r93, -1;
	.loc	1 343 22
	mov.u32 	%r5, %tid.x;
	setp.eq.s32 	%p38, %r5, 0;
	mov.u32 	%r65, global_smem;
	add.s32 	%r61, %r65, 147456;
	// begin inline asm
	@%p38 mbarrier.init.shared::cta.b64 [%r61], 1;
	// end inline asm
	bar.sync 	0;
	add.s32 	%r123, %r65, 147464;
	// begin inline asm
	@%p38 mbarrier.init.shared::cta.b64 [%r123], 1;
	// end inline asm
	bar.sync 	0;
	add.s32 	%r63, %r65, 147472;
	// begin inline asm
	@%p38 mbarrier.init.shared::cta.b64 [%r63], 1;
	// end inline asm
	setp.gt.s32 	%p11, %r3, 0;
	.loc	1 347 34
	div.s32 	%r102, %r326, %r6;
	.loc	1 348 37
	shl.b32 	%r103, %r102, 3;
	.loc	1 349 43
	sub.s32 	%r104, %r81, %r103;
	.loc	1 349 56
	min.s32 	%r105, %r104, 8;
	.loc	1 350 45
	rem.s32 	%r106, %r326, %r105;
	.loc	1 350 35
	add.s32 	%r107, %r103, %r106;
	mul.lo.s32 	%r108, %r102, %r6;
	sub.s32 	%r109, %r326, %r108;
	.loc	1 351 52
	div.s32 	%r110, %r109, %r105;
	.loc	1 353 30
	shl.b32 	%r316, %r107, 7;
	.loc	1 354 30
	shl.b32 	%r315, %r110, 8;
	.loc	1 343 22
	bar.sync 	0;
	and.pred  	%p6, %p38, %p11;
	// begin inline asm
	@%p6 mbarrier.arrive.expect_tx.shared.b64 _, [%r61], 49152;
	// end inline asm
	.loc	1 358 106
	bar.sync 	0;
	shr.u32 	%r9, %r5, 5;
	shfl.sync.idx.b32	%r111, %r9, 0, 31, -1;
	// begin inline asm
	elect.sync _|%p7, 0xffffffff;
	// end inline asm
	and.pred  	%p12, %p11, %p7;
	setp.lt.u32 	%p13, %r5, 32;
	and.pred  	%p8, %p13, %p12;
	mov.b32 	%r66, 0;
	// begin inline asm
	@%p8 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r65], [%rd16, {%r66, %r316}], [%r61];
	// end inline asm
	.loc	1 359 106
	bar.sync 	0;
	shfl.sync.idx.b32	%r112, %r9, 0, 31, -1;
	add.s32 	%r69, %r65, 49152;
	// begin inline asm
	@%p8 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r69], [%rd17, {%r66, %r315}], [%r61];
	// end inline asm
	.loc	1 344 0
	setp.ne.s32 	%p14, %r4, 0;
	mov.b32 	%r311, 64;
	mov.u32 	%r322, %r316;
	mov.u32 	%r321, %r315;
	.loc	1 345 11
	@%p14 bra 	$L__BB0_2;
	.loc	1 346 23
	add.s32 	%r326, %r326, 132;
	.loc	1 347 34
	div.s32 	%r114, %r326, %r6;
	.loc	1 348 37
	shl.b32 	%r115, %r114, 3;
	.loc	1 349 43
	sub.s32 	%r116, %r81, %r115;
	.loc	1 349 56
	min.s32 	%r117, %r116, 8;
	.loc	1 350 45
	rem.s32 	%r118, %r326, %r117;
	.loc	1 350 35
	add.s32 	%r119, %r115, %r118;
	mul.lo.s32 	%r120, %r114, %r6;
	sub.s32 	%r121, %r326, %r120;
	.loc	1 351 52
	div.s32 	%r122, %r121, %r117;
	.loc	1 353 30
	shl.b32 	%r322, %r119, 7;
	.loc	1 354 30
	shl.b32 	%r321, %r122, 8;
	mov.u32 	%r311, %r66;
$L__BB0_2:
	.loc	1 343 22
	setp.gt.s32 	%p18, %r3, 1;
	setp.lt.s32 	%p20, %r3, 1;
	bar.sync 	0;
	and.pred  	%p15, %p38, %p18;
	// begin inline asm
	@%p15 mbarrier.arrive.expect_tx.shared.b64 _, [%r123], 49152;
	// end inline asm
	.loc	1 358 106
	bar.sync 	0;
	shfl.sync.idx.b32	%r133, %r9, 0, 31, -1;
	and.pred  	%p22, %p18, %p7;
	and.pred  	%p16, %p13, %p22;
	add.s32 	%r124, %r65, 16384;
	// begin inline asm
	@%p16 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r124], [%rd16, {%r311, %r322}], [%r123];
	// end inline asm
	.loc	1 359 106
	bar.sync 	0;
	shfl.sync.idx.b32	%r134, %r9, 0, 31, -1;
	add.s32 	%r128, %r65, 81920;
	// begin inline asm
	@%p16 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r128], [%rd17, {%r311, %r321}], [%r123];
	// end inline asm
	mov.f32 	%f2348, 0f00000000;
	mov.f32 	%f2349, %f2348;
	mov.f32 	%f2350, %f2348;
	mov.f32 	%f2351, %f2348;
	mov.f32 	%f2352, %f2348;
	mov.f32 	%f2353, %f2348;
	mov.f32 	%f2354, %f2348;
	mov.f32 	%f2355, %f2348;
	mov.f32 	%f2356, %f2348;
	mov.f32 	%f2357, %f2348;
	mov.f32 	%f2358, %f2348;
	mov.f32 	%f2359, %f2348;
	mov.f32 	%f2360, %f2348;
	mov.f32 	%f2361, %f2348;
	mov.f32 	%f2362, %f2348;
	mov.f32 	%f2363, %f2348;
	mov.f32 	%f2364, %f2348;
	mov.f32 	%f2365, %f2348;
	mov.f32 	%f2366, %f2348;
	mov.f32 	%f2367, %f2348;
	mov.f32 	%f2368, %f2348;
	mov.f32 	%f2369, %f2348;
	mov.f32 	%f2370, %f2348;
	mov.f32 	%f2371, %f2348;
	mov.f32 	%f2372, %f2348;
	mov.f32 	%f2373, %f2348;
	mov.f32 	%f2374, %f2348;
	mov.f32 	%f2375, %f2348;
	mov.f32 	%f2376, %f2348;
	mov.f32 	%f2377, %f2348;
	mov.f32 	%f2378, %f2348;
	mov.f32 	%f2379, %f2348;
	mov.f32 	%f2380, %f2348;
	mov.f32 	%f2381, %f2348;
	mov.f32 	%f2382, %f2348;
	mov.f32 	%f2383, %f2348;
	mov.f32 	%f2384, %f2348;
	mov.f32 	%f2385, %f2348;
	mov.f32 	%f2386, %f2348;
	mov.f32 	%f2387, %f2348;
	mov.f32 	%f2388, %f2348;
	mov.f32 	%f2389, %f2348;
	mov.f32 	%f2390, %f2348;
	mov.f32 	%f2391, %f2348;
	mov.f32 	%f2392, %f2348;
	mov.f32 	%f2393, %f2348;
	mov.f32 	%f2394, %f2348;
	mov.f32 	%f2395, %f2348;
	mov.f32 	%f2396, %f2348;
	mov.f32 	%f2397, %f2348;
	mov.f32 	%f2398, %f2348;
	mov.f32 	%f2399, %f2348;
	mov.f32 	%f2400, %f2348;
	mov.f32 	%f2401, %f2348;
	mov.f32 	%f2402, %f2348;
	mov.f32 	%f2403, %f2348;
	mov.f32 	%f2404, %f2348;
	mov.f32 	%f2405, %f2348;
	mov.f32 	%f2406, %f2348;
	mov.f32 	%f2407, %f2348;
	mov.f32 	%f2408, %f2348;
	mov.f32 	%f2409, %f2348;
	mov.f32 	%f2410, %f2348;
	mov.f32 	%f2411, %f2348;
	mov.f32 	%f2412, %f2348;
	mov.f32 	%f2413, %f2348;
	mov.f32 	%f2414, %f2348;
	mov.f32 	%f2415, %f2348;
	mov.f32 	%f2416, %f2348;
	mov.f32 	%f2417, %f2348;
	mov.f32 	%f2418, %f2348;
	mov.f32 	%f2419, %f2348;
	mov.f32 	%f2420, %f2348;
	mov.f32 	%f2421, %f2348;
	mov.f32 	%f2422, %f2348;
	mov.f32 	%f2423, %f2348;
	mov.f32 	%f2424, %f2348;
	mov.f32 	%f2425, %f2348;
	mov.f32 	%f2426, %f2348;
	mov.f32 	%f2427, %f2348;
	mov.f32 	%f2428, %f2348;
	mov.f32 	%f2429, %f2348;
	mov.f32 	%f2430, %f2348;
	mov.f32 	%f2431, %f2348;
	mov.f32 	%f2432, %f2348;
	mov.f32 	%f2433, %f2348;
	mov.f32 	%f2434, %f2348;
	mov.f32 	%f2435, %f2348;
	mov.f32 	%f2436, %f2348;
	mov.f32 	%f2437, %f2348;
	mov.f32 	%f2438, %f2348;
	mov.f32 	%f2439, %f2348;
	mov.f32 	%f2440, %f2348;
	mov.f32 	%f2441, %f2348;
	mov.f32 	%f2442, %f2348;
	mov.f32 	%f2443, %f2348;
	mov.f32 	%f2444, %f2348;
	mov.f32 	%f2445, %f2348;
	mov.f32 	%f2446, %f2348;
	mov.f32 	%f2447, %f2348;
	mov.f32 	%f2448, %f2348;
	mov.f32 	%f2449, %f2348;
	mov.f32 	%f2450, %f2348;
	mov.f32 	%f2451, %f2348;
	mov.f32 	%f2452, %f2348;
	mov.f32 	%f2453, %f2348;
	mov.f32 	%f2454, %f2348;
	mov.f32 	%f2455, %f2348;
	mov.f32 	%f2456, %f2348;
	mov.f32 	%f2457, %f2348;
	mov.f32 	%f2458, %f2348;
	mov.f32 	%f2459, %f2348;
	mov.f32 	%f2460, %f2348;
	mov.f32 	%f2461, %f2348;
	mov.f32 	%f2462, %f2348;
	mov.f32 	%f2463, %f2348;
	mov.f32 	%f2464, %f2348;
	mov.f32 	%f2465, %f2348;
	mov.f32 	%f2466, %f2348;
	mov.f32 	%f2467, %f2348;
	mov.f32 	%f2468, %f2348;
	mov.f32 	%f2469, %f2348;
	mov.f32 	%f2470, %f2348;
	mov.f32 	%f2471, %f2348;
	mov.f32 	%f2472, %f2348;
	mov.f32 	%f2473, %f2348;
	mov.f32 	%f2474, %f2348;
	mov.f32 	%f2475, %f2348;
	.loc	1 343 22
	@%p20 bra 	$L__BB0_9;
	.loc	1 0 22
	ld.param.u64 	%rd24, [matmul_kernel_tma_persistent_OVERRIDE_param_2];
	selp.u32 	%r324, 1, 0, %p14;
	add.s32 	%r18, %r3, -2;
	and.b32  	%r19, %r9, 134217724;
	shl.b32 	%r138, %r5, 1;
	and.b32  	%r139, %r138, 6;
	bfe.s32 	%r140, %r5, 2, 1;
	and.b32  	%r141, %r140, 72;
	or.b32  	%r142, %r141, %r139;
	bfe.s32 	%r143, %r5, 3, 1;
	and.b32  	%r144, %r143, 144;
	or.b32  	%r145, %r142, %r144;
	and.b32  	%r146, %r5, 16;
	shl.b32 	%r147, %r146, 1;
	or.b32  	%r148, %r145, %r147;
	bfe.u32 	%r149, %r5, 4, 1;
	shr.u32 	%r150, %r5, 3;
	and.b32  	%r151, %r150, 28;
	or.b32  	%r152, %r149, %r151;
	shl.b32 	%r153, %r152, 8;
	or.b32  	%r154, %r148, %r153;
	shl.b32 	%r155, %r154, 1;
	add.s32 	%r157, %r65, 148480;
	add.s32 	%r20, %r157, %r155;
	or.b32  	%r158, %r139, 8;
	xor.b32  	%r159, %r158, %r141;
	or.b32  	%r160, %r147, %r159;
	or.b32  	%r161, %r160, %r144;
	or.b32  	%r162, %r161, %r153;
	shl.b32 	%r163, %r162, 1;
	add.s32 	%r22, %r157, %r163;
	or.b32  	%r164, %r142, 16;
	xor.b32  	%r165, %r164, %r144;
	or.b32  	%r166, %r165, %r147;
	or.b32  	%r167, %r166, %r153;
	shl.b32 	%r168, %r167, 1;
	add.s32 	%r24, %r157, %r168;
	or.b32  	%r169, %r139, 24;
	or.b32  	%r170, %r144, %r141;
	xor.b32  	%r171, %r170, %r169;
	or.b32  	%r172, %r171, %r147;
	or.b32  	%r173, %r172, %r153;
	shl.b32 	%r174, %r173, 1;
	add.s32 	%r26, %r157, %r174;
	or.b32  	%r175, %r145, 32;
	xor.b32  	%r176, %r175, %r147;
	or.b32  	%r177, %r176, %r153;
	shl.b32 	%r178, %r177, 1;
	add.s32 	%r28, %r157, %r178;
	or.b32  	%r179, %r139, 40;
	xor.b32  	%r180, %r179, %r141;
	or.b32  	%r181, %r180, %r144;
	xor.b32  	%r182, %r181, %r147;
	or.b32  	%r183, %r182, %r153;
	shl.b32 	%r184, %r183, 1;
	add.s32 	%r30, %r157, %r184;
	or.b32  	%r185, %r142, 48;
	or.b32  	%r186, %r144, %r147;
	xor.b32  	%r187, %r186, %r185;
	or.b32  	%r188, %r187, %r153;
	shl.b32 	%r189, %r188, 1;
	add.s32 	%r32, %r157, %r189;
	or.b32  	%r190, %r139, 56;
	or.b32  	%r191, %r186, %r141;
	xor.b32  	%r192, %r191, %r190;
	or.b32  	%r193, %r192, %r153;
	shl.b32 	%r194, %r193, 1;
	add.s32 	%r34, %r157, %r194;
	setp.lt.u32 	%p23, %r5, 128;
	and.pred  	%p36, %p23, %p7;
	mov.f32 	%f2348, 0f00000000;
	mov.b32 	%r320, 1;
	mov.b32 	%r319, -1;
	mov.b32 	%r317, 0;
	mov.u32 	%r318, %r317;
	mov.f32 	%f2349, %f2348;
	mov.f32 	%f2350, %f2348;
	mov.f32 	%f2351, %f2348;
	mov.f32 	%f2352, %f2348;
	mov.f32 	%f2353, %f2348;
	mov.f32 	%f2354, %f2348;
	mov.f32 	%f2355, %f2348;
	mov.f32 	%f2356, %f2348;
	mov.f32 	%f2357, %f2348;
	mov.f32 	%f2358, %f2348;
	mov.f32 	%f2359, %f2348;
	mov.f32 	%f2360, %f2348;
	mov.f32 	%f2361, %f2348;
	mov.f32 	%f2362, %f2348;
	mov.f32 	%f2363, %f2348;
	mov.f32 	%f2364, %f2348;
	mov.f32 	%f2365, %f2348;
	mov.f32 	%f2366, %f2348;
	mov.f32 	%f2367, %f2348;
	mov.f32 	%f2368, %f2348;
	mov.f32 	%f2369, %f2348;
	mov.f32 	%f2370, %f2348;
	mov.f32 	%f2371, %f2348;
	mov.f32 	%f2372, %f2348;
	mov.f32 	%f2373, %f2348;
	mov.f32 	%f2374, %f2348;
	mov.f32 	%f2375, %f2348;
	mov.f32 	%f2376, %f2348;
	mov.f32 	%f2377, %f2348;
	mov.f32 	%f2378, %f2348;
	mov.f32 	%f2379, %f2348;
	mov.f32 	%f2380, %f2348;
	mov.f32 	%f2381, %f2348;
	mov.f32 	%f2382, %f2348;
	mov.f32 	%f2383, %f2348;
	mov.f32 	%f2384, %f2348;
	mov.f32 	%f2385, %f2348;
	mov.f32 	%f2386, %f2348;
	mov.f32 	%f2387, %f2348;
	mov.f32 	%f2388, %f2348;
	mov.f32 	%f2389, %f2348;
	mov.f32 	%f2390, %f2348;
	mov.f32 	%f2391, %f2348;
	mov.f32 	%f2392, %f2348;
	mov.f32 	%f2393, %f2348;
	mov.f32 	%f2394, %f2348;
	mov.f32 	%f2395, %f2348;
	mov.f32 	%f2396, %f2348;
	mov.f32 	%f2397, %f2348;
	mov.f32 	%f2398, %f2348;
	mov.f32 	%f2399, %f2348;
	mov.f32 	%f2400, %f2348;
	mov.f32 	%f2401, %f2348;
	mov.f32 	%f2402, %f2348;
	mov.f32 	%f2403, %f2348;
	mov.f32 	%f2404, %f2348;
	mov.f32 	%f2405, %f2348;
	mov.f32 	%f2406, %f2348;
	mov.f32 	%f2407, %f2348;
	mov.f32 	%f2408, %f2348;
	mov.f32 	%f2409, %f2348;
	mov.f32 	%f2410, %f2348;
	mov.f32 	%f2411, %f2348;
	mov.f32 	%f2412, %f2348;
	mov.f32 	%f2413, %f2348;
	mov.f32 	%f2414, %f2348;
	mov.f32 	%f2415, %f2348;
	mov.f32 	%f2416, %f2348;
	mov.f32 	%f2417, %f2348;
	mov.f32 	%f2418, %f2348;
	mov.f32 	%f2419, %f2348;
	mov.f32 	%f2420, %f2348;
	mov.f32 	%f2421, %f2348;
	mov.f32 	%f2422, %f2348;
	mov.f32 	%f2423, %f2348;
	mov.f32 	%f2424, %f2348;
	mov.f32 	%f2425, %f2348;
	mov.f32 	%f2426, %f2348;
	mov.f32 	%f2427, %f2348;
	mov.f32 	%f2428, %f2348;
	mov.f32 	%f2429, %f2348;
	mov.f32 	%f2430, %f2348;
	mov.f32 	%f2431, %f2348;
	mov.f32 	%f2432, %f2348;
	mov.f32 	%f2433, %f2348;
	mov.f32 	%f2434, %f2348;
	mov.f32 	%f2435, %f2348;
	mov.f32 	%f2436, %f2348;
	mov.f32 	%f2437, %f2348;
	mov.f32 	%f2438, %f2348;
	mov.f32 	%f2439, %f2348;
	mov.f32 	%f2440, %f2348;
	mov.f32 	%f2441, %f2348;
	mov.f32 	%f2442, %f2348;
	mov.f32 	%f2443, %f2348;
	mov.f32 	%f2444, %f2348;
	mov.f32 	%f2445, %f2348;
	mov.f32 	%f2446, %f2348;
	mov.f32 	%f2447, %f2348;
	mov.f32 	%f2448, %f2348;
	mov.f32 	%f2449, %f2348;
	mov.f32 	%f2450, %f2348;
	mov.f32 	%f2451, %f2348;
	mov.f32 	%f2452, %f2348;
	mov.f32 	%f2453, %f2348;
	mov.f32 	%f2454, %f2348;
	mov.f32 	%f2455, %f2348;
	mov.f32 	%f2456, %f2348;
	mov.f32 	%f2457, %f2348;
	mov.f32 	%f2458, %f2348;
	mov.f32 	%f2459, %f2348;
	mov.f32 	%f2460, %f2348;
	mov.f32 	%f2461, %f2348;
	mov.f32 	%f2462, %f2348;
	mov.f32 	%f2463, %f2348;
	mov.f32 	%f2464, %f2348;
	mov.f32 	%f2465, %f2348;
	mov.f32 	%f2466, %f2348;
	mov.f32 	%f2467, %f2348;
	mov.f32 	%f2468, %f2348;
	mov.f32 	%f2469, %f2348;
	mov.f32 	%f2470, %f2348;
	mov.f32 	%f2471, %f2348;
	mov.f32 	%f2472, %f2348;
	mov.f32 	%f2473, %f2348;
	mov.f32 	%f2474, %f2348;
	mov.f32 	%f2475, %f2348;
	mov.u32 	%r325, %r317;
	mov.u32 	%r327, %r322;
	mov.u32 	%r328, %r321;
	bra.uni 	$L__BB0_4;
$L__BB0_8:
	.loc	1 343 22
	add.s32 	%r325, %r325, 1;
	setp.lt.s32 	%p37, %r325, %r3;
	mov.u32 	%r315, %r321;
	mov.u32 	%r316, %r322;
	mov.u32 	%r317, %r324;
	mov.u32 	%r321, %r328;
	mov.u32 	%r322, %r327;
	mov.u32 	%r324, %r47;
	@%p37 bra 	$L__BB0_4;
	bra.uni 	$L__BB0_9;
$L__BB0_4:
	.loc	1 344 28
	setp.eq.s32 	%p24, %r324, %r4;
	.loc	1 344 49
	add.s32 	%r195, %r324, 1;
	.loc	1 344 44
	selp.b32 	%r47, 0, %r195, %p24;
	.loc	1 345 17
	setp.ne.s32 	%p25, %r47, 0;
	.loc	1 345 11
	@%p25 bra 	$L__BB0_6;
	.loc	1 346 23
	add.s32 	%r326, %r326, 132;
	.loc	1 347 34
	div.s32 	%r196, %r326, %r6;
	.loc	1 348 37
	shl.b32 	%r197, %r196, 3;
	.loc	1 349 43
	sub.s32 	%r198, %r81, %r197;
	.loc	1 349 56
	min.s32 	%r199, %r198, 8;
	.loc	1 350 45
	rem.s32 	%r200, %r326, %r199;
	.loc	1 350 35
	add.s32 	%r201, %r197, %r200;
	mul.lo.s32 	%r202, %r196, %r6;
	sub.s32 	%r203, %r326, %r202;
	.loc	1 351 52
	div.s32 	%r204, %r203, %r199;
	.loc	1 353 30
	shl.b32 	%r327, %r201, 7;
	.loc	1 354 30
	shl.b32 	%r328, %r204, 8;
$L__BB0_6:
	.loc	1 343 22
	setp.lt.s32 	%p29, %r325, %r18;
	add.s32 	%r216, %r319, 1;
	setp.gt.s32 	%p32, %r216, 2;
	selp.b32 	%r319, 0, %r216, %p32;
	selp.u32 	%r217, 1, 0, %p32;
	xor.b32  	%r318, %r318, %r217;
	shl.b32 	%r218, %r319, 3;
	add.s32 	%r205, %r61, %r218;
	bar.sync 	0;
	// begin inline asm
	{                                                           
	.reg .pred P1;                                              
	waitLoop:                                                   
	mbarrier.try_wait.parity.shared.b64 P1, [%r205], %r318;           
	@!P1 bra.uni waitLoop;                                      
	}                                                           
	
	// end inline asm
	.loc	1 359 106
	shl.b32 	%r221, %r319, 14;
	shl.b32 	%r222, %r319, 15;
	add.s32 	%r56, %r69, %r222;
	.loc	1 358 106
	add.s32 	%r57, %r65, %r221;
	.loc	1 360 37
	shfl.sync.idx.b32	%r224, %r19, 0, 31, -1;
	// begin inline asm
	wgmma.fence.sync.aligned;
	// end inline asm
	shl.b32 	%r225, %r224, 7;
	and.b32  	%r226, %r225, 896;
	cvt.u64.u32 	%rd18, %r226;
	shr.u32 	%r227, %r57, 4;
	cvt.u64.u32 	%rd19, %r227;
	and.b64  	%rd20, %rd19, 16383;
	add.s64 	%rd21, %rd20, %rd18;
	or.b64  	%rd8, %rd21, 4611686293372403712;
	shr.u32 	%r228, %r56, 4;
	cvt.u64.u32 	%rd22, %r228;
	and.b64  	%rd23, %rd22, 16383;
	or.b64  	%rd9, %rd23, 4611686293439512576;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n256k16.f32.f16.f16 {%f2348,%f2349,%f2350,%f2351,%f2352,%f2353,%f2354,%f2355,%f2356,%f2357,%f2358,%f2359,%f2360,%f2361,%f2362,%f2363,%f2364,%f2365,%f2366,%f2367,%f2368,%f2369,%f2370,%f2371,%f2372,%f2373,%f2374,%f2375,%f2376,%f2377,%f2378,%f2379,%f2380,%f2381,%f2382,%f2383,%f2384,%f2385,%f2386,%f2387,%f2388,%f2389,%f2390,%f2391,%f2392,%f2393,%f2394,%f2395,%f2396,%f2397,%f2398,%f2399,%f2400,%f2401,%f2402,%f2403,%f2404,%f2405,%f2406,%f2407,%f2408,%f2409,%f2410,%f2411,%f2412,%f2413,%f2414,%f2415,%f2416,%f2417,%f2418,%f2419,%f2420,%f2421,%f2422,%f2423,%f2424,%f2425,%f2426,%f2427,%f2428,%f2429,%f2430,%f2431,%f2432,%f2433,%f2434,%f2435,%f2436,%f2437,%f2438,%f2439,%f2440,%f2441,%f2442,%f2443,%f2444,%f2445,%f2446,%f2447,%f2448,%f2449,%f2450,%f2451,%f2452,%f2453,%f2454,%f2455,%f2456,%f2457,%f2458,%f2459,%f2460,%f2461,%f2462,%f2463,%f2464,%f2465,%f2466,%f2467,%f2468,%f2469,%f2470,%f2471,%f2472,%f2473,%f2474,%f2475}, %rd8, %rd9, 1, 1, 1, 0, 0;
	// end inline asm
	add.s64 	%rd10, %rd21, 4611686293372403714;
	add.s64 	%rd11, %rd23, 4611686293439512578;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n256k16.f32.f16.f16 {%f2348,%f2349,%f2350,%f2351,%f2352,%f2353,%f2354,%f2355,%f2356,%f2357,%f2358,%f2359,%f2360,%f2361,%f2362,%f2363,%f2364,%f2365,%f2366,%f2367,%f2368,%f2369,%f2370,%f2371,%f2372,%f2373,%f2374,%f2375,%f2376,%f2377,%f2378,%f2379,%f2380,%f2381,%f2382,%f2383,%f2384,%f2385,%f2386,%f2387,%f2388,%f2389,%f2390,%f2391,%f2392,%f2393,%f2394,%f2395,%f2396,%f2397,%f2398,%f2399,%f2400,%f2401,%f2402,%f2403,%f2404,%f2405,%f2406,%f2407,%f2408,%f2409,%f2410,%f2411,%f2412,%f2413,%f2414,%f2415,%f2416,%f2417,%f2418,%f2419,%f2420,%f2421,%f2422,%f2423,%f2424,%f2425,%f2426,%f2427,%f2428,%f2429,%f2430,%f2431,%f2432,%f2433,%f2434,%f2435,%f2436,%f2437,%f2438,%f2439,%f2440,%f2441,%f2442,%f2443,%f2444,%f2445,%f2446,%f2447,%f2448,%f2449,%f2450,%f2451,%f2452,%f2453,%f2454,%f2455,%f2456,%f2457,%f2458,%f2459,%f2460,%f2461,%f2462,%f2463,%f2464,%f2465,%f2466,%f2467,%f2468,%f2469,%f2470,%f2471,%f2472,%f2473,%f2474,%f2475}, %rd10, %rd11, 1, 1, 1, 0, 0;
	// end inline asm
	add.s64 	%rd12, %rd21, 4611686293372403716;
	add.s64 	%rd13, %rd23, 4611686293439512580;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n256k16.f32.f16.f16 {%f2348,%f2349,%f2350,%f2351,%f2352,%f2353,%f2354,%f2355,%f2356,%f2357,%f2358,%f2359,%f2360,%f2361,%f2362,%f2363,%f2364,%f2365,%f2366,%f2367,%f2368,%f2369,%f2370,%f2371,%f2372,%f2373,%f2374,%f2375,%f2376,%f2377,%f2378,%f2379,%f2380,%f2381,%f2382,%f2383,%f2384,%f2385,%f2386,%f2387,%f2388,%f2389,%f2390,%f2391,%f2392,%f2393,%f2394,%f2395,%f2396,%f2397,%f2398,%f2399,%f2400,%f2401,%f2402,%f2403,%f2404,%f2405,%f2406,%f2407,%f2408,%f2409,%f2410,%f2411,%f2412,%f2413,%f2414,%f2415,%f2416,%f2417,%f2418,%f2419,%f2420,%f2421,%f2422,%f2423,%f2424,%f2425,%f2426,%f2427,%f2428,%f2429,%f2430,%f2431,%f2432,%f2433,%f2434,%f2435,%f2436,%f2437,%f2438,%f2439,%f2440,%f2441,%f2442,%f2443,%f2444,%f2445,%f2446,%f2447,%f2448,%f2449,%f2450,%f2451,%f2452,%f2453,%f2454,%f2455,%f2456,%f2457,%f2458,%f2459,%f2460,%f2461,%f2462,%f2463,%f2464,%f2465,%f2466,%f2467,%f2468,%f2469,%f2470,%f2471,%f2472,%f2473,%f2474,%f2475}, %rd12, %rd13, 1, 1, 1, 0, 0;
	// end inline asm
	add.s64 	%rd14, %rd21, 4611686293372403718;
	add.s64 	%rd15, %rd23, 4611686293439512582;
	// begin inline asm
	wgmma.mma_async.sync.aligned.m64n256k16.f32.f16.f16 {%f2348,%f2349,%f2350,%f2351,%f2352,%f2353,%f2354,%f2355,%f2356,%f2357,%f2358,%f2359,%f2360,%f2361,%f2362,%f2363,%f2364,%f2365,%f2366,%f2367,%f2368,%f2369,%f2370,%f2371,%f2372,%f2373,%f2374,%f2375,%f2376,%f2377,%f2378,%f2379,%f2380,%f2381,%f2382,%f2383,%f2384,%f2385,%f2386,%f2387,%f2388,%f2389,%f2390,%f2391,%f2392,%f2393,%f2394,%f2395,%f2396,%f2397,%f2398,%f2399,%f2400,%f2401,%f2402,%f2403,%f2404,%f2405,%f2406,%f2407,%f2408,%f2409,%f2410,%f2411,%f2412,%f2413,%f2414,%f2415,%f2416,%f2417,%f2418,%f2419,%f2420,%f2421,%f2422,%f2423,%f2424,%f2425,%f2426,%f2427,%f2428,%f2429,%f2430,%f2431,%f2432,%f2433,%f2434,%f2435,%f2436,%f2437,%f2438,%f2439,%f2440,%f2441,%f2442,%f2443,%f2444,%f2445,%f2446,%f2447,%f2448,%f2449,%f2450,%f2451,%f2452,%f2453,%f2454,%f2455,%f2456,%f2457,%f2458,%f2459,%f2460,%f2461,%f2462,%f2463,%f2464,%f2465,%f2466,%f2467,%f2468,%f2469,%f2470,%f2471,%f2472,%f2473,%f2474,%f2475}, %rd14, %rd15, 1, 1, 1, 0, 0;
	// end inline asm
	// begin inline asm
	wgmma.commit_group.sync.aligned;
	// end inline asm
	mov.b32 	%f1943, %r57;
	mov.b32 	%f1948, %r56;
	mov.f32 	%f1945, 0f00000001;
	mov.f32 	%f1950, 0f00000040;
	mov.f32 	%f2084, 0f00000000;
	mov.f32 	%f1672, %f1948;
	mov.f32 	%f1673, %f1945;
	mov.f32 	%f1667, %f1943;
	mov.f32 	%f1674, %f1950;
	mov.f32 	%f1668, %f1950;
	mov.f32 	%f1669, %f1945;
	mov.f32 	%f1676, %f2084;
	mov.f32 	%f1670, %f2084;
	mov.f32 	%f1671, %f2084;
	mov.f32 	%f1675, %f2084;
	// begin inline asm
	// wait for regs: %f2348,%f2349,%f2350,%f2351,%f2352,%f2353,%f2354,%f2355,%f2356,%f2357,%f2358,%f2359,%f2360,%f2361,%f2362,%f2363,%f2364,%f2365,%f2366,%f2367,%f2368,%f2369,%f2370,%f2371,%f2372,%f2373,%f2374,%f2375,%f2376,%f2377,%f2378,%f2379,%f2380,%f2381,%f2382,%f2383,%f2384,%f2385,%f2386,%f2387,%f2388,%f2389,%f2390,%f2391,%f2392,%f2393,%f2394,%f2395,%f2396,%f2397,%f2398,%f2399,%f2400,%f2401,%f2402,%f2403,%f2404,%f2405,%f2406,%f2407,%f2408,%f2409,%f2410,%f2411,%f2412,%f2413,%f2414,%f2415,%f2416,%f2417,%f2418,%f2419,%f2420,%f2421,%f2422,%f2423,%f2424,%f2425,%f2426,%f2427,%f2428,%f2429,%f2430,%f2431,%f2432,%f2433,%f2434,%f2435,%f2436,%f2437,%f2438,%f2439,%f2440,%f2441,%f2442,%f2443,%f2444,%f2445,%f2446,%f2447,%f2448,%f2449,%f2450,%f2451,%f2452,%f2453,%f2454,%f2455,%f2456,%f2457,%f2458,%f2459,%f2460,%f2461,%f2462,%f2463,%f2464,%f2465,%f2466,%f2467,%f2468,%f2469,%f2470,%f2471,%f2472,%f2473,%f2474,%f2475,%f1667,%f1668,%f1669,%f1670,%f1671,%f1672,%f1673,%f1674,%f1675,%f1676
	wgmma.wait_group.sync.aligned 1;
	// end inline asm
	.loc	1 343 22
	add.s32 	%r229, %r320, 1;
	setp.lt.s32 	%p33, %r229, 3;
	selp.b32 	%r320, %r229, 0, %p33;
	.loc	1 356 22
	shl.b32 	%r209, %r47, 6;
	.loc	1 343 22
	shl.b32 	%r230, %r320, 3;
	add.s32 	%r207, %r61, %r230;
	bar.sync 	0;
	and.pred  	%p26, %p38, %p29;
	// begin inline asm
	@%p26 mbarrier.arrive.expect_tx.shared.b64 _, [%r207], 49152;
	// end inline asm
	.loc	1 358 106
	shl.b32 	%r231, %r320, 14;
	add.s32 	%r208, %r65, %r231;
	bar.sync 	0;
	shfl.sync.idx.b32	%r232, %r9, 0, 31, -1;
	and.pred  	%p34, %p7, %p29;
	and.pred  	%p27, %p13, %p34;
	// begin inline asm
	@%p27 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r208], [%rd16, {%r209, %r327}], [%r207];
	// end inline asm
	.loc	1 359 106
	shl.b32 	%r233, %r320, 15;
	add.s32 	%r212, %r69, %r233;
	bar.sync 	0;
	shfl.sync.idx.b32	%r234, %r9, 0, 31, -1;
	// begin inline asm
	@%p27 cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes [%r212], [%rd17, {%r209, %r328}], [%r207];
	// end inline asm
	.loc	1 362 17
	setp.ne.s32 	%p35, %r317, %r4;
	.loc	1 362 11
	@%p35 bra 	$L__BB0_8;
	.loc	1 360 37
	mov.f32 	%f1949, %f1945;
	mov.f32 	%f1946, %f2084;
	mov.f32 	%f1947, %f2084;
	mov.f32 	%f1951, %f2084;
	mov.f32 	%f1952, %f2084;
	mov.f32 	%f1944, %f1950;
	// begin inline asm
	// wait for regs: %f2348,%f2349,%f2350,%f2351,%f2352,%f2353,%f2354,%f2355,%f2356,%f2357,%f2358,%f2359,%f2360,%f2361,%f2362,%f2363,%f2364,%f2365,%f2366,%f2367,%f2368,%f2369,%f2370,%f2371,%f2372,%f2373,%f2374,%f2375,%f2376,%f2377,%f2378,%f2379,%f2380,%f2381,%f2382,%f2383,%f2384,%f2385,%f2386,%f2387,%f2388,%f2389,%f2390,%f2391,%f2392,%f2393,%f2394,%f2395,%f2396,%f2397,%f2398,%f2399,%f2400,%f2401,%f2402,%f2403,%f2404,%f2405,%f2406,%f2407,%f2408,%f2409,%f2410,%f2411,%f2412,%f2413,%f2414,%f2415,%f2416,%f2417,%f2418,%f2419,%f2420,%f2421,%f2422,%f2423,%f2424,%f2425,%f2426,%f2427,%f2428,%f2429,%f2430,%f2431,%f2432,%f2433,%f2434,%f2435,%f2436,%f2437,%f2438,%f2439,%f2440,%f2441,%f2442,%f2443,%f2444,%f2445,%f2446,%f2447,%f2448,%f2449,%f2450,%f2451,%f2452,%f2453,%f2454,%f2455,%f2456,%f2457,%f2458,%f2459,%f2460,%f2461,%f2462,%f2463,%f2464,%f2465,%f2466,%f2467,%f2468,%f2469,%f2470,%f2471,%f2472,%f2473,%f2474,%f2475,%f1943,%f1944,%f1945,%f1946,%f1947,%f1948,%f1949,%f1950,%f1951,%f1952
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	.loc	1 363 31
	cvt.rn.f16.f32 	%rs1, %f2349;
	cvt.rn.f16.f32 	%rs2, %f2348;
	mov.b32 	%r238, {%rs2, %rs1};
	cvt.rn.f16.f32 	%rs3, %f2351;
	cvt.rn.f16.f32 	%rs4, %f2350;
	mov.b32 	%r239, {%rs4, %rs3};
	cvt.rn.f16.f32 	%rs5, %f2353;
	cvt.rn.f16.f32 	%rs6, %f2352;
	mov.b32 	%r240, {%rs6, %rs5};
	cvt.rn.f16.f32 	%rs7, %f2355;
	cvt.rn.f16.f32 	%rs8, %f2354;
	mov.b32 	%r241, {%rs8, %rs7};
	cvt.rn.f16.f32 	%rs9, %f2357;
	cvt.rn.f16.f32 	%rs10, %f2356;
	mov.b32 	%r242, {%rs10, %rs9};
	cvt.rn.f16.f32 	%rs11, %f2359;
	cvt.rn.f16.f32 	%rs12, %f2358;
	mov.b32 	%r243, {%rs12, %rs11};
	cvt.rn.f16.f32 	%rs13, %f2361;
	cvt.rn.f16.f32 	%rs14, %f2360;
	mov.b32 	%r244, {%rs14, %rs13};
	cvt.rn.f16.f32 	%rs15, %f2363;
	cvt.rn.f16.f32 	%rs16, %f2362;
	mov.b32 	%r245, {%rs16, %rs15};
	cvt.rn.f16.f32 	%rs17, %f2365;
	cvt.rn.f16.f32 	%rs18, %f2364;
	mov.b32 	%r246, {%rs18, %rs17};
	cvt.rn.f16.f32 	%rs19, %f2367;
	cvt.rn.f16.f32 	%rs20, %f2366;
	mov.b32 	%r247, {%rs20, %rs19};
	cvt.rn.f16.f32 	%rs21, %f2369;
	cvt.rn.f16.f32 	%rs22, %f2368;
	mov.b32 	%r248, {%rs22, %rs21};
	cvt.rn.f16.f32 	%rs23, %f2371;
	cvt.rn.f16.f32 	%rs24, %f2370;
	mov.b32 	%r249, {%rs24, %rs23};
	cvt.rn.f16.f32 	%rs25, %f2373;
	cvt.rn.f16.f32 	%rs26, %f2372;
	mov.b32 	%r250, {%rs26, %rs25};
	cvt.rn.f16.f32 	%rs27, %f2375;
	cvt.rn.f16.f32 	%rs28, %f2374;
	mov.b32 	%r251, {%rs28, %rs27};
	cvt.rn.f16.f32 	%rs29, %f2377;
	cvt.rn.f16.f32 	%rs30, %f2376;
	mov.b32 	%r252, {%rs30, %rs29};
	cvt.rn.f16.f32 	%rs31, %f2379;
	cvt.rn.f16.f32 	%rs32, %f2378;
	mov.b32 	%r253, {%rs32, %rs31};
	cvt.rn.f16.f32 	%rs33, %f2381;
	cvt.rn.f16.f32 	%rs34, %f2380;
	mov.b32 	%r254, {%rs34, %rs33};
	cvt.rn.f16.f32 	%rs35, %f2383;
	cvt.rn.f16.f32 	%rs36, %f2382;
	mov.b32 	%r255, {%rs36, %rs35};
	cvt.rn.f16.f32 	%rs37, %f2385;
	cvt.rn.f16.f32 	%rs38, %f2384;
	mov.b32 	%r256, {%rs38, %rs37};
	cvt.rn.f16.f32 	%rs39, %f2387;
	cvt.rn.f16.f32 	%rs40, %f2386;
	mov.b32 	%r257, {%rs40, %rs39};
	cvt.rn.f16.f32 	%rs41, %f2389;
	cvt.rn.f16.f32 	%rs42, %f2388;
	mov.b32 	%r258, {%rs42, %rs41};
	cvt.rn.f16.f32 	%rs43, %f2391;
	cvt.rn.f16.f32 	%rs44, %f2390;
	mov.b32 	%r259, {%rs44, %rs43};
	cvt.rn.f16.f32 	%rs45, %f2393;
	cvt.rn.f16.f32 	%rs46, %f2392;
	mov.b32 	%r260, {%rs46, %rs45};
	cvt.rn.f16.f32 	%rs47, %f2395;
	cvt.rn.f16.f32 	%rs48, %f2394;
	mov.b32 	%r261, {%rs48, %rs47};
	cvt.rn.f16.f32 	%rs49, %f2397;
	cvt.rn.f16.f32 	%rs50, %f2396;
	mov.b32 	%r262, {%rs50, %rs49};
	cvt.rn.f16.f32 	%rs51, %f2399;
	cvt.rn.f16.f32 	%rs52, %f2398;
	mov.b32 	%r263, {%rs52, %rs51};
	cvt.rn.f16.f32 	%rs53, %f2401;
	cvt.rn.f16.f32 	%rs54, %f2400;
	mov.b32 	%r264, {%rs54, %rs53};
	cvt.rn.f16.f32 	%rs55, %f2403;
	cvt.rn.f16.f32 	%rs56, %f2402;
	mov.b32 	%r265, {%rs56, %rs55};
	cvt.rn.f16.f32 	%rs57, %f2405;
	cvt.rn.f16.f32 	%rs58, %f2404;
	mov.b32 	%r266, {%rs58, %rs57};
	cvt.rn.f16.f32 	%rs59, %f2407;
	cvt.rn.f16.f32 	%rs60, %f2406;
	mov.b32 	%r267, {%rs60, %rs59};
	cvt.rn.f16.f32 	%rs61, %f2409;
	cvt.rn.f16.f32 	%rs62, %f2408;
	mov.b32 	%r268, {%rs62, %rs61};
	cvt.rn.f16.f32 	%rs63, %f2411;
	cvt.rn.f16.f32 	%rs64, %f2410;
	mov.b32 	%r269, {%rs64, %rs63};
	cvt.rn.f16.f32 	%rs65, %f2413;
	cvt.rn.f16.f32 	%rs66, %f2412;
	mov.b32 	%r270, {%rs66, %rs65};
	cvt.rn.f16.f32 	%rs67, %f2415;
	cvt.rn.f16.f32 	%rs68, %f2414;
	mov.b32 	%r271, {%rs68, %rs67};
	cvt.rn.f16.f32 	%rs69, %f2417;
	cvt.rn.f16.f32 	%rs70, %f2416;
	mov.b32 	%r272, {%rs70, %rs69};
	cvt.rn.f16.f32 	%rs71, %f2419;
	cvt.rn.f16.f32 	%rs72, %f2418;
	mov.b32 	%r273, {%rs72, %rs71};
	cvt.rn.f16.f32 	%rs73, %f2421;
	cvt.rn.f16.f32 	%rs74, %f2420;
	mov.b32 	%r274, {%rs74, %rs73};
	cvt.rn.f16.f32 	%rs75, %f2423;
	cvt.rn.f16.f32 	%rs76, %f2422;
	mov.b32 	%r275, {%rs76, %rs75};
	cvt.rn.f16.f32 	%rs77, %f2425;
	cvt.rn.f16.f32 	%rs78, %f2424;
	mov.b32 	%r276, {%rs78, %rs77};
	cvt.rn.f16.f32 	%rs79, %f2427;
	cvt.rn.f16.f32 	%rs80, %f2426;
	mov.b32 	%r277, {%rs80, %rs79};
	cvt.rn.f16.f32 	%rs81, %f2429;
	cvt.rn.f16.f32 	%rs82, %f2428;
	mov.b32 	%r278, {%rs82, %rs81};
	cvt.rn.f16.f32 	%rs83, %f2431;
	cvt.rn.f16.f32 	%rs84, %f2430;
	mov.b32 	%r279, {%rs84, %rs83};
	cvt.rn.f16.f32 	%rs85, %f2433;
	cvt.rn.f16.f32 	%rs86, %f2432;
	mov.b32 	%r280, {%rs86, %rs85};
	cvt.rn.f16.f32 	%rs87, %f2435;
	cvt.rn.f16.f32 	%rs88, %f2434;
	mov.b32 	%r281, {%rs88, %rs87};
	cvt.rn.f16.f32 	%rs89, %f2437;
	cvt.rn.f16.f32 	%rs90, %f2436;
	mov.b32 	%r282, {%rs90, %rs89};
	cvt.rn.f16.f32 	%rs91, %f2439;
	cvt.rn.f16.f32 	%rs92, %f2438;
	mov.b32 	%r283, {%rs92, %rs91};
	cvt.rn.f16.f32 	%rs93, %f2441;
	cvt.rn.f16.f32 	%rs94, %f2440;
	mov.b32 	%r284, {%rs94, %rs93};
	cvt.rn.f16.f32 	%rs95, %f2443;
	cvt.rn.f16.f32 	%rs96, %f2442;
	mov.b32 	%r285, {%rs96, %rs95};
	cvt.rn.f16.f32 	%rs97, %f2445;
	cvt.rn.f16.f32 	%rs98, %f2444;
	mov.b32 	%r286, {%rs98, %rs97};
	cvt.rn.f16.f32 	%rs99, %f2447;
	cvt.rn.f16.f32 	%rs100, %f2446;
	mov.b32 	%r287, {%rs100, %rs99};
	cvt.rn.f16.f32 	%rs101, %f2449;
	cvt.rn.f16.f32 	%rs102, %f2448;
	mov.b32 	%r288, {%rs102, %rs101};
	cvt.rn.f16.f32 	%rs103, %f2451;
	cvt.rn.f16.f32 	%rs104, %f2450;
	mov.b32 	%r289, {%rs104, %rs103};
	cvt.rn.f16.f32 	%rs105, %f2453;
	cvt.rn.f16.f32 	%rs106, %f2452;
	mov.b32 	%r290, {%rs106, %rs105};
	cvt.rn.f16.f32 	%rs107, %f2455;
	cvt.rn.f16.f32 	%rs108, %f2454;
	mov.b32 	%r291, {%rs108, %rs107};
	cvt.rn.f16.f32 	%rs109, %f2457;
	cvt.rn.f16.f32 	%rs110, %f2456;
	mov.b32 	%r292, {%rs110, %rs109};
	cvt.rn.f16.f32 	%rs111, %f2459;
	cvt.rn.f16.f32 	%rs112, %f2458;
	mov.b32 	%r293, {%rs112, %rs111};
	cvt.rn.f16.f32 	%rs113, %f2461;
	cvt.rn.f16.f32 	%rs114, %f2460;
	mov.b32 	%r294, {%rs114, %rs113};
	cvt.rn.f16.f32 	%rs115, %f2463;
	cvt.rn.f16.f32 	%rs116, %f2462;
	mov.b32 	%r295, {%rs116, %rs115};
	cvt.rn.f16.f32 	%rs117, %f2465;
	cvt.rn.f16.f32 	%rs118, %f2464;
	mov.b32 	%r296, {%rs118, %rs117};
	cvt.rn.f16.f32 	%rs119, %f2467;
	cvt.rn.f16.f32 	%rs120, %f2466;
	mov.b32 	%r297, {%rs120, %rs119};
	cvt.rn.f16.f32 	%rs121, %f2469;
	cvt.rn.f16.f32 	%rs122, %f2468;
	mov.b32 	%r298, {%rs122, %rs121};
	cvt.rn.f16.f32 	%rs123, %f2471;
	cvt.rn.f16.f32 	%rs124, %f2470;
	mov.b32 	%r299, {%rs124, %rs123};
	cvt.rn.f16.f32 	%rs125, %f2473;
	cvt.rn.f16.f32 	%rs126, %f2472;
	mov.b32 	%r300, {%rs126, %rs125};
	cvt.rn.f16.f32 	%rs127, %f2475;
	cvt.rn.f16.f32 	%rs128, %f2474;
	mov.b32 	%r301, {%rs128, %rs127};
	.loc	1 365 61
	// begin inline asm
	cp.async.bulk.wait_group.read 0x0;
	// end inline asm
	st.shared.b32 	[%r20], %r238;
	st.shared.b32 	[%r20+1024], %r239;
	st.shared.b32 	[%r22], %r240;
	st.shared.b32 	[%r22+1024], %r241;
	st.shared.b32 	[%r24], %r242;
	st.shared.b32 	[%r24+1024], %r243;
	st.shared.b32 	[%r26], %r244;
	st.shared.b32 	[%r26+1024], %r245;
	st.shared.b32 	[%r28], %r246;
	st.shared.b32 	[%r28+1024], %r247;
	st.shared.b32 	[%r30], %r248;
	st.shared.b32 	[%r30+1024], %r249;
	st.shared.b32 	[%r32], %r250;
	st.shared.b32 	[%r32+1024], %r251;
	st.shared.b32 	[%r34], %r252;
	st.shared.b32 	[%r34+1024], %r253;
	st.shared.b32 	[%r20+16384], %r254;
	st.shared.b32 	[%r20+17408], %r255;
	st.shared.b32 	[%r22+16384], %r256;
	st.shared.b32 	[%r22+17408], %r257;
	st.shared.b32 	[%r24+16384], %r258;
	st.shared.b32 	[%r24+17408], %r259;
	st.shared.b32 	[%r26+16384], %r260;
	st.shared.b32 	[%r26+17408], %r261;
	st.shared.b32 	[%r28+16384], %r262;
	st.shared.b32 	[%r28+17408], %r263;
	st.shared.b32 	[%r30+16384], %r264;
	st.shared.b32 	[%r30+17408], %r265;
	st.shared.b32 	[%r32+16384], %r266;
	st.shared.b32 	[%r32+17408], %r267;
	st.shared.b32 	[%r34+16384], %r268;
	st.shared.b32 	[%r34+17408], %r269;
	st.shared.b32 	[%r20+32768], %r270;
	st.shared.b32 	[%r20+33792], %r271;
	st.shared.b32 	[%r22+32768], %r272;
	st.shared.b32 	[%r22+33792], %r273;
	st.shared.b32 	[%r24+32768], %r274;
	st.shared.b32 	[%r24+33792], %r275;
	st.shared.b32 	[%r26+32768], %r276;
	st.shared.b32 	[%r26+33792], %r277;
	st.shared.b32 	[%r28+32768], %r278;
	st.shared.b32 	[%r28+33792], %r279;
	st.shared.b32 	[%r30+32768], %r280;
	st.shared.b32 	[%r30+33792], %r281;
	st.shared.b32 	[%r32+32768], %r282;
	st.shared.b32 	[%r32+33792], %r283;
	st.shared.b32 	[%r34+32768], %r284;
	st.shared.b32 	[%r34+33792], %r285;
	st.shared.b32 	[%r20+49152], %r286;
	st.shared.b32 	[%r20+50176], %r287;
	st.shared.b32 	[%r22+49152], %r288;
	st.shared.b32 	[%r22+50176], %r289;
	st.shared.b32 	[%r24+49152], %r290;
	st.shared.b32 	[%r24+50176], %r291;
	st.shared.b32 	[%r26+49152], %r292;
	st.shared.b32 	[%r26+50176], %r293;
	st.shared.b32 	[%r28+49152], %r294;
	st.shared.b32 	[%r28+50176], %r295;
	st.shared.b32 	[%r30+49152], %r296;
	st.shared.b32 	[%r30+50176], %r297;
	st.shared.b32 	[%r32+49152], %r298;
	st.shared.b32 	[%r32+50176], %r299;
	st.shared.b32 	[%r34+49152], %r300;
	st.shared.b32 	[%r34+50176], %r301;
	// begin inline asm
	fence.proxy.async.shared::cta;
	// end inline asm
	bar.sync 	0;
	shfl.sync.idx.b32	%r302, %r9, 0, 31, -1;
	shl.b32 	%r303, %r302, 14;
	add.s32 	%r305, %r65, %r303;
	add.s32 	%r237, %r305, 148480;
	shl.b32 	%r306, %r302, 6;
	add.s32 	%r235, %r306, %r315;
	// begin inline asm
	@%p36 cp.async.bulk.tensor.2d.global.shared::cta.bulk_group [%rd24, {%r235, %r316}], [%r237];
	// end inline asm
	// begin inline asm
	cp.async.bulk.commit_group ;
	// end inline asm
	mov.f32 	%f2348, %f2084;
	mov.f32 	%f2349, %f2084;
	mov.f32 	%f2350, %f2084;
	mov.f32 	%f2351, %f2084;
	mov.f32 	%f2352, %f2084;
	mov.f32 	%f2353, %f2084;
	mov.f32 	%f2354, %f2084;
	mov.f32 	%f2355, %f2084;
	mov.f32 	%f2356, %f2084;
	mov.f32 	%f2357, %f2084;
	mov.f32 	%f2358, %f2084;
	mov.f32 	%f2359, %f2084;
	mov.f32 	%f2360, %f2084;
	mov.f32 	%f2361, %f2084;
	mov.f32 	%f2362, %f2084;
	mov.f32 	%f2363, %f2084;
	mov.f32 	%f2364, %f2084;
	mov.f32 	%f2365, %f2084;
	mov.f32 	%f2366, %f2084;
	mov.f32 	%f2367, %f2084;
	mov.f32 	%f2368, %f2084;
	mov.f32 	%f2369, %f2084;
	mov.f32 	%f2370, %f2084;
	mov.f32 	%f2371, %f2084;
	mov.f32 	%f2372, %f2084;
	mov.f32 	%f2373, %f2084;
	mov.f32 	%f2374, %f2084;
	mov.f32 	%f2375, %f2084;
	mov.f32 	%f2376, %f2084;
	mov.f32 	%f2377, %f2084;
	mov.f32 	%f2378, %f2084;
	mov.f32 	%f2379, %f2084;
	mov.f32 	%f2380, %f2084;
	mov.f32 	%f2381, %f2084;
	mov.f32 	%f2382, %f2084;
	mov.f32 	%f2383, %f2084;
	mov.f32 	%f2384, %f2084;
	mov.f32 	%f2385, %f2084;
	mov.f32 	%f2386, %f2084;
	mov.f32 	%f2387, %f2084;
	mov.f32 	%f2388, %f2084;
	mov.f32 	%f2389, %f2084;
	mov.f32 	%f2390, %f2084;
	mov.f32 	%f2391, %f2084;
	mov.f32 	%f2392, %f2084;
	mov.f32 	%f2393, %f2084;
	mov.f32 	%f2394, %f2084;
	mov.f32 	%f2395, %f2084;
	mov.f32 	%f2396, %f2084;
	mov.f32 	%f2397, %f2084;
	mov.f32 	%f2398, %f2084;
	mov.f32 	%f2399, %f2084;
	mov.f32 	%f2400, %f2084;
	mov.f32 	%f2401, %f2084;
	mov.f32 	%f2402, %f2084;
	mov.f32 	%f2403, %f2084;
	mov.f32 	%f2404, %f2084;
	mov.f32 	%f2405, %f2084;
	mov.f32 	%f2406, %f2084;
	mov.f32 	%f2407, %f2084;
	mov.f32 	%f2408, %f2084;
	mov.f32 	%f2409, %f2084;
	mov.f32 	%f2410, %f2084;
	mov.f32 	%f2411, %f2084;
	mov.f32 	%f2412, %f2084;
	mov.f32 	%f2413, %f2084;
	mov.f32 	%f2414, %f2084;
	mov.f32 	%f2415, %f2084;
	mov.f32 	%f2416, %f2084;
	mov.f32 	%f2417, %f2084;
	mov.f32 	%f2418, %f2084;
	mov.f32 	%f2419, %f2084;
	mov.f32 	%f2420, %f2084;
	mov.f32 	%f2421, %f2084;
	mov.f32 	%f2422, %f2084;
	mov.f32 	%f2423, %f2084;
	mov.f32 	%f2424, %f2084;
	mov.f32 	%f2425, %f2084;
	mov.f32 	%f2426, %f2084;
	mov.f32 	%f2427, %f2084;
	mov.f32 	%f2428, %f2084;
	mov.f32 	%f2429, %f2084;
	mov.f32 	%f2430, %f2084;
	mov.f32 	%f2431, %f2084;
	mov.f32 	%f2432, %f2084;
	mov.f32 	%f2433, %f2084;
	mov.f32 	%f2434, %f2084;
	mov.f32 	%f2435, %f2084;
	mov.f32 	%f2436, %f2084;
	mov.f32 	%f2437, %f2084;
	mov.f32 	%f2438, %f2084;
	mov.f32 	%f2439, %f2084;
	mov.f32 	%f2440, %f2084;
	mov.f32 	%f2441, %f2084;
	mov.f32 	%f2442, %f2084;
	mov.f32 	%f2443, %f2084;
	mov.f32 	%f2444, %f2084;
	mov.f32 	%f2445, %f2084;
	mov.f32 	%f2446, %f2084;
	mov.f32 	%f2447, %f2084;
	mov.f32 	%f2448, %f2084;
	mov.f32 	%f2449, %f2084;
	mov.f32 	%f2450, %f2084;
	mov.f32 	%f2451, %f2084;
	mov.f32 	%f2452, %f2084;
	mov.f32 	%f2453, %f2084;
	mov.f32 	%f2454, %f2084;
	mov.f32 	%f2455, %f2084;
	mov.f32 	%f2456, %f2084;
	mov.f32 	%f2457, %f2084;
	mov.f32 	%f2458, %f2084;
	mov.f32 	%f2459, %f2084;
	mov.f32 	%f2460, %f2084;
	mov.f32 	%f2461, %f2084;
	mov.f32 	%f2462, %f2084;
	mov.f32 	%f2463, %f2084;
	mov.f32 	%f2464, %f2084;
	mov.f32 	%f2465, %f2084;
	mov.f32 	%f2466, %f2084;
	mov.f32 	%f2467, %f2084;
	mov.f32 	%f2468, %f2084;
	mov.f32 	%f2469, %f2084;
	mov.f32 	%f2470, %f2084;
	mov.f32 	%f2471, %f2084;
	mov.f32 	%f2472, %f2084;
	mov.f32 	%f2473, %f2084;
	mov.f32 	%f2474, %f2084;
	mov.f32 	%f2475, %f2084;
	bra.uni 	$L__BB0_8;
$L__BB0_9:
	.loc	1 343 22
	// begin inline asm
	cp.async.bulk.wait_group.read 0x0;
	// end inline asm
	// begin inline asm
	// wait for regs: %f2348,%f2349,%f2350,%f2351,%f2352,%f2353,%f2354,%f2355,%f2356,%f2357,%f2358,%f2359,%f2360,%f2361,%f2362,%f2363,%f2364,%f2365,%f2366,%f2367,%f2368,%f2369,%f2370,%f2371,%f2372,%f2373,%f2374,%f2375,%f2376,%f2377,%f2378,%f2379,%f2380,%f2381,%f2382,%f2383,%f2384,%f2385,%f2386,%f2387,%f2388,%f2389,%f2390,%f2391,%f2392,%f2393,%f2394,%f2395,%f2396,%f2397,%f2398,%f2399,%f2400,%f2401,%f2402,%f2403,%f2404,%f2405,%f2406,%f2407,%f2408,%f2409,%f2410,%f2411,%f2412,%f2413,%f2414,%f2415,%f2416,%f2417,%f2418,%f2419,%f2420,%f2421,%f2422,%f2423,%f2424,%f2425,%f2426,%f2427,%f2428,%f2429,%f2430,%f2431,%f2432,%f2433,%f2434,%f2435,%f2436,%f2437,%f2438,%f2439,%f2440,%f2441,%f2442,%f2443,%f2444,%f2445,%f2446,%f2447,%f2448,%f2449,%f2450,%f2451,%f2452,%f2453,%f2454,%f2455,%f2456,%f2457,%f2458,%f2459,%f2460,%f2461,%f2462,%f2463,%f2464,%f2465,%f2466,%f2467,%f2468,%f2469,%f2470,%f2471,%f2472,%f2473,%f2474,%f2475
	wgmma.wait_group.sync.aligned 0;
	// end inline asm
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p38 mbarrier.inval.shared::cta.b64 [%r61];
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p38 mbarrier.inval.shared::cta.b64 [%r123];
	// end inline asm
	bar.sync 	0;
	// begin inline asm
	@%p38 mbarrier.inval.shared::cta.b64 [%r63];
	// end inline asm
	.loc	1 343 4
	ret;
$L__tmp4:
$L__func_end0:

}
	.file	1 "/data/users/embg/triton/python/tutorials/09-persistent-matmul.py"
	.file	2 "/data/users/embg/triton/python/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 1
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 2
.b8 46
.b8 0
.b8 3
.b8 8
.b8 32
.b8 11
.b8 0
.b8 0
.b8 3
.b8 46
.b8 1
.b8 17
.b8 1
.b8 18
.b8 1
.b8 49
.b8 19
.b8 0
.b8 0
.b8 4
.b8 29
.b8 0
.b8 49
.b8 19
.b8 17
.b8 1
.b8 18
.b8 1
.b8 88
.b8 11
.b8 89
.b8 5
.b8 87
.b8 11
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 215
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 48
.b8 57
.b8 45
.b8 112
.b8 101
.b8 114
.b8 115
.b8 105
.b8 115
.b8 116
.b8 101
.b8 110
.b8 116
.b8 45
.b8 109
.b8 97
.b8 116
.b8 109
.b8 117
.b8 108
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 47
.b8 100
.b8 97
.b8 116
.b8 97
.b8 47
.b8 117
.b8 115
.b8 101
.b8 114
.b8 115
.b8 47
.b8 101
.b8 109
.b8 98
.b8 103
.b8 47
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 47
.b8 112
.b8 121
.b8 116
.b8 104
.b8 111
.b8 110
.b8 47
.b8 116
.b8 117
.b8 116
.b8 111
.b8 114
.b8 105
.b8 97
.b8 108
.b8 115
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
.b8 2
.b8 109
.b8 97
.b8 116
.b8 109
.b8 117
.b8 108
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 95
.b8 116
.b8 109
.b8 97
.b8 95
.b8 112
.b8 101
.b8 114
.b8 115
.b8 105
.b8 115
.b8 116
.b8 101
.b8 110
.b8 116
.b8 95
.b8 79
.b8 86
.b8 69
.b8 82
.b8 82
.b8 73
.b8 68
.b8 69
.b8 0
.b8 1
.b8 3
.b64 $L__func_begin0
.b64 $L__func_end0
.b32 106
.b8 4
.b32 106
.b64 $L__tmp1
.b64 $L__tmp2
.b8 1
.b8 67
.b8 1
.b8 27
.b8 4
.b32 106
.b64 $L__tmp2
.b64 $L__tmp3
.b8 1
.b8 68
.b8 1
.b8 25
.b8 0
.b8 0
	}
	.section	.debug_loc	{	}
